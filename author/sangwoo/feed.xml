<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="https://blog.airlab.re.kr/author/sangwoo/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://blog.airlab.re.kr/" rel="alternate" type="text/html" />
  <updated>2019-11-27T18:51:22+09:00</updated>
  <id>https://blog.airlab.re.kr/author/sangwoo/feed.xml</id>

  
  
  

  
    <title type="html">AiRLab. Research Blog | </title>
  

  
    <subtitle>Artificial intelligence and Robotics Laboratory</subtitle>
  

  

  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
  

  
    <entry>
      <title type="html">Exploring Randomly Wired Neural Networks for Image Recognition</title>
      <link href="https://blog.airlab.re.kr/2019/11/Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition" rel="alternate" type="text/html" title="Exploring Randomly Wired Neural Networks for Image Recognition" />
      <published>2019-11-26T19:00:00+09:00</published>
      <updated>2019-11-26T19:00:00+09:00</updated>
      <id>https://blog.airlab.re.kr/2019/11/Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition</id>
      <content type="html" xml:base="https://blog.airlab.re.kr/2019/11/Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition">&lt;p&gt;안녕하세요 AiRLab 이상우입니다. 이번에 읽어본 논문은 Exploring Randomly Wired Neural Networks for Image Recognition 으로 Network Architecture 를 Random 하게 만들어보면 어떨까? 하는 생각을 가진 논문입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;introduction&quot;&gt;&lt;strong&gt;&lt;u&gt;Introduction&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-26-Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition/figure_r_1.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;논문 저자는 네트워크의 정규한 패턴의 연결이 있는 Network Architecture가 꾸준히 발전해왔으며 이러한 연결들을 랜덤하게 연결하면 어떻게 되는지 실험을 해보았다고 합니다. 결과는 생각보다 놀라웠으며 기존의 Network 보다 성능이 더 좋거나 성능을 견줄만한 결과를 보여주었다고 합니다. 이로써 Network Architecture를 수동적으로 개발하는 것보다는 앞으로 Network generator 를 개발하는 것이 더 좋을 것이다라는 생각을 가지고 있습니다.&lt;br /&gt;
자세하기 알아보기전에 이 논문은 랜덤하게 연결을 해보면 어떨까? 라는 것이 메인 아이디어인만큼 사실 인공지능에서 큰 영감을 줄만한 내용보다는 어떻게 하면 Network를 랜덤하게 연결하는지와 관련된 내용이 논문의 주된 구성입니다.
하지만 제 생각에는 이 논문이 Network Architecture 의 연구 방향을 바꿀만한 논문이라 다들 한번씩 읽어보시면 좋을거 같습니다. 이제 자세한 내용을 소개해드리겠습니다.&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;methodology&quot;&gt;&lt;strong&gt;&lt;u&gt;Methodology&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;이 논문에서 소개하는 Network generator 는  &lt;strong&gt;g(Θ,s)&lt;/strong&gt; 라는 값을 가지고 네트워크를 생성합니다. 이 값이 가지는 의미를 하나하나 설명하겠습니다. &lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Θ&lt;/strong&gt; : 네트워크의 다양한 정보를 포함하고 있는 값입니다. 예를 들어 VGG generator 가 있다면 VGG-16 으로 만들건지 VGG-34로 만들지를 결정하고 Network 의 깊이,폭,필터의 크기 등을 지정할 수 있습니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;g&lt;/strong&gt; : graph의 연결을 결정합니다. 예를 들면 ResNet generator 가 있다면 F(x)의 값을 연결을 g를 통해서 x+f(x) 를 만들어 주는 값입니다. &lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;g(Θ)&lt;/strong&gt; : 집합 N을 반환합니다. 위에 값으로 생성된 연결과 설정을 가지고 만든 네트워크를 반환합니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;s&lt;/strong&gt; : 이 과정을 몇번 반복할 것인지 정합니다. g(θ) 를 몇번 호출하여 랜덤 네트워크 패밀리를 구성할 수 있습니다.&lt;br /&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-26-Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition/figure_r_2.png&quot; width=&quot;200&quot; hight=&quot;70&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;논문 저자는 random graph 를 생성하고, 생성된 graph를 가지고 Network에 매핑을 시키는 방식을 가지고 만들었습니다. 그래서 Network generator 는 일반적인 graph를 생성하며 시작되고, 노드를 연결하는 일련의 노드와 edge를 생성합니다. edge는 위에 그림에서 보이는 노드로 들어오거나 나가는 화살표이며, 이는 데이더의 Flow라고 합니다. 파란색 원으로 구성된 부분은 노드라고 부르며 노드는 들어오는 데이터는 weight의 합계를 통해 conv로 들어가며 conv 는 ReLu - convolution - BN triplet 로 구성되어있다고 합니다. 또 노드는 몇개의 Input,Output edge를 가질 수 있다고 합니다. 이를 통해 graph 이론의 일반 graph 생성기를 자유롭게 사용하며 graph를 얻으면 신경망에 매핑이 된다고 합니다.&lt;/p&gt;

&lt;h4 id=&quot;random-graph-models&quot;&gt;&lt;strong&gt;&lt;u&gt;Random Graph Models&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-26-Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition/figure_r_3.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위에 보시다 싶이 3가지 방법으로 짜여진 graph들이 있습니다. 이는 위에서 설명한 일반 graph 생성기로 생성된 graph들이며 이 방법들이 어떻게 사용되었는지 설명을 해드리겠습니다.&lt;br /&gt;
첫번째 방법으로는 Erdos-R ˝ enyi 으로 &lt;strong&gt;ER&lt;/strong&gt;로 표시하고 있습니다. ER 은 N의 노드를 사용하는 경우, 임의의 두개의 노드는 다른 노드들과는 무관하게 edge가 P의 확률로 연결이 된다고 합니다. 이 방법은 모든 노드 쌍에 대해서 반복되며 ER은 P의 확률만을 가지고 있기때문에 ER(P) 로 표시한다고 합니다. &lt;br /&gt;
두번째 방법으로는 Barabasi-Albert 으로 &lt;strong&gt;BA&lt;/strong&gt;로 표시하고 있습니다. BA 은 순차적으로 새 노드를 추가하여 랜덤 graph를 생성하며 초기 상태는 edge가 없는 M노드부터 시작된다고 합니다. 이 방법은 순차적으로 M개의 edge가 있는 노드가 생성될 때까지 반복하며, 중복되는 방향의 edge는 생성하지 않는다고 합니다. 이 과정은 N개의 노드가 생길 때까지 반복하며, BA는 단일 파라미터 M을 가지며, BA(M)으로 표시됩니다. &lt;br /&gt;
세번째 방법으로는 Watts-Strogatz 으로 &lt;strong&gt;WS&lt;/strong&gt;로 표시하고 있습니다. WS 은 처음에 N노드는 정기적으로 링에 배치되고 각 노드는 인접한 K/2에 연결된다고 합니다. 그런 다음 시계방향 루프에서 모든 노드 V에 대해 시계방향 I번째 다음 노드에 연결하는 edge가 P의 확률로 연결이 됩니다. I는 1 ≤ i ≤ K/2 이며 K/2 번 반복된다고 합니다. &lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;experiments&quot;&gt;&lt;strong&gt;&lt;u&gt;Experiments&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-26-Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition/figure_r_4.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;figure1. Comparison on random graph generators : ER,BA, and WS&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;일반 graph 생성기 3개로 생성된 네트워크들의 정확도를 비교한 사진입니다. 직관적으로 보이는 결과이니 자세한 설명은 생략하겠습니다. &lt;br /&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-26-Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition/figure_r_5.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;figure2. ImageNet: small computation regime&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이 논문 저자가 생성한 랜덤 네트워크로 다른 논문의 네트워크들과 비교했을 때도 정확도 면에서 경쟁력이 있는 결과는 보여줍니다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-26-Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition/figure_r_6.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;figure3. ImageNet: large computation regime.&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이 결과는 FLOPs와 params 수가 현저히 적은데도 불구하고 다른 네트워크들과 비슷한 정확도를 보여주고 있습니다. 가장 정확도가 좋은 PNASNNet-5와 1.3% 가 나지만 FLOPs와 params 수가 확실히 차이가 나는것을 보실 수 있습니다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-26-Exploring-Randomly-Wired-Neural-Networks-for-Image-Recognition/figure_r_7.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;figure4. COCO object detection&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;COCO dataset 에서 backbone을 ResNet과 ResNext를 사용했을 때 보다 RandWire를 썻을 때 정확도가 전체적으로 향상되있는 것을 볼수 있습니다. FLOP은 비슷하거나 더 낮다고 하였습니다.&lt;br /&gt;
논문을 마치며 저의 생각은 앞으로 네트워크 구조의 발전이 네트워크 생성기의 설계쪽으로 기울어져 갈것같습니다. 비록 논문의 내용이 인공지능에 영감을 줄만한 내용은 충분히 있었다고는 생각하지 않았으나 네트워크 구조에 대한 방향성이 바뀔 수 있는 논문이라 충분히 읽어볼만 하다고 생각합니다. 부족한 점은 저의 메일이나 댓글로 남겨주세요. 감사합니다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sangwoo Lee</name>
        
        
      </author>

      

      
        <category term="paper-review" />
      

      
        <summary type="html">안녕하세요 AiRLab 이상우입니다. 이번에 읽어본 논문은 Exploring Randomly Wired Neural Networks for Image Recognition 으로 Network Architecture 를 Random 하게 만들어보면 어떨까? 하는 생각을 가진 논문입니다.</summary>
      

      
      
    </entry>
  
    <entry>
      <title type="html">SlowFast Network for Video Recognition</title>
      <link href="https://blog.airlab.re.kr/2019/11/SlowFast" rel="alternate" type="text/html" title="SlowFast Network for Video Recognition" />
      <published>2019-11-13T06:00:00+09:00</published>
      <updated>2019-11-13T06:00:00+09:00</updated>
      <id>https://blog.airlab.re.kr/2019/11/SlowFast</id>
      <content type="html" xml:base="https://blog.airlab.re.kr/2019/11/SlowFast">&lt;p&gt;안녕하세요? 이번에 &lt;strong&gt;SlowFast&lt;/strong&gt; 논문 Review를 하게된 &lt;strong&gt;AirLab&lt;/strong&gt; 이상우입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;introduction&quot;&gt;&lt;strong&gt;&lt;u&gt;Introduction&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;SlowFast는 Video Recognition 을 위한 네트워크 구조입니다. 이 네트워크는 FAIR (FaceBook Artificial Intelligence Research) 에서 발표한 논문으로
이전의 다른 네트워크들과의 다른점은 Opticalflow 를 사용하지 않은 영상 인식 네트워크 였다는 것입니다. 이로써 End-To-End 학습이 영상인식에서도 가능해졌다고 합니다.
이 논문은 영장류의 물체의 행동을 인식하는 세포에서 영감을 받았다고 하는데 자세한 내용은 밑에서 알아보도록 하겠습니다.&lt;/p&gt;

&lt;h4 id=&quot;slowfast-networks&quot;&gt;&lt;strong&gt;&lt;u&gt;SlowFast Networks&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-08-SlowFast/figure1.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;

&lt;center&gt;(figure1. SlowFast Networks)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;SlowFast는 2가지의 Pathway가 있습니다. 위에 보이는 Pathway는 Slow pathway라고 부르며, 이 Pathway는 낮은 프레임으로 주어질 수 있는 의미적 정보를 포착하도록
설계가 되었다고 합니다. 간단한 예를 들면 박수라는 행동에서 손이라는 객체를 파악하는데 힘을 싣는 경로입니다. 반대로 Fast Pathway의 경우는 높은 프레임속도로 빠르게 변화하는
움직임을 포착하는 역할을 합니다. 이 부분이 기존 영상인식에서 Opticalflow 로 수행되었던 부분입니다.
Slow Pathway는 τ 값을 가지는데 대표적으로 16을 사용하였다고 합니다. 이 값은 30프레임의 영상의 경우 30프레임중에 약 2프레임 정도의 이미지만 뽑아준다고 합니다.
Fast Pathway는 t/α 값을 가지고 α의 값을 1 이상의 값을 가진다고 합니다. 논문 저자는 대표적으로 8의 값을 사용하였다고 합니다. (t = 전체 프레임) 30프레임 인 경우
약 4프레임 정도의 이미지를 뽑게 됩니다.
이 논문에서 중요한 부분은 Fast Pathway인데 이 부분은 전체 연산량의 20% 밖에 수행하지 않는다고 합니다. 저는 처음에 보고 많은 프레임을 다루는데 더 많은 연산량이
사용될거라 생각했는데 이 부분에서 중요한 아이디어가 있었습니다. Fast Pathway의 경우 위에서 Opticalflow 를 대체해서 사용된 부분이고, 움직임을 포착하는 것을 위해
설계되었다고 하였습니다. 이 부분에서 느낌이 오신분이 있을수도 있는데요. 결론적으로 &lt;strong&gt;많은 채널의 정보를 사용하지 않습니다.&lt;/strong&gt; 단순히 예를 들어 말씀을 드리면, 박수라는 행동을
인식하기 위해서 손을 인식해야되고 손이 무엇을 할수 있는지 파악을 해야합니다. 그래서 의미적 정보를 파악할 때 손이라는 객체의 색상이 살색이라면 조금 더 쉽게 손을 파악할 수 있습니다.
하지만 손이라는 정보를 알고선 행동을 파악할 떄는 손이 회색,노란색이라도 손이라는 정보를 안다면 박수라는 행동을 쉽게 인식할 수 있습니다.
논문에서는 공간과 차원에 대한 특별한 처리가 없기때문에 채널의 수가 적어도 된다고 설명이 되어있으며, 즉 이는 &lt;strong&gt;계산이 가벼워지고 처리속도가 빨라지게&lt;/strong&gt; 되었다고 합니다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-08-SlowFast/figure2.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(figure2. An example instantiation of the SlowFast network)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위에 이미지를 참조하시면 조금 더 이해에 도움이 되실겁니다. 초록색의 경우 Fast Pathway에서 나오는 프레임입니다. Slow Pathway보다 높은 프레임률을 사용하고 있다는
것이 확인이 됩니다. 노란색의 경우 Fast Pathway에서 사용하는 채널의 수를 보여줍니다. Slow Pathway에서 사용하는 값의 1/8 정도의 채널의 수를 사용하고 있는것도 확인이 됩니다.&lt;/p&gt;

&lt;p&gt;그런데 이쯤에서 궁금한 점이 생기셨을 겁니다. 각각의 Pathway에서 나온 출력값은 다른 형태를 띄고 있는데 어떻게 두 개를 합쳐서 영상 인식을 하게 되는걸까요?
이 부분에서는 Lateral Connections 라는 방식을 사용하여서 간단히 두개의 값의 형태를 맞춰줍니다.
Slow pathway  = {T, S^2, C}
Fast pathway  = {αT, S^2, βC}
각각 pathway에서 나온 feature의 형태는 이러한 형태를 띄는데 3가지 방식을 중점으로 형태를 바꿔주게 됩니다.
[1]. Time-to-channel : {αT, S^2, βC} 이러한 feature의 형태를 {T, S^2, αβC} 형태로 바꿔줍니다. 즉 α값을 하나 프레임의 채널로 변환을 시킵니다.
[2]. Time-strided sampling : {αT, S^2, βC} α프레임 중 하나만 샘플링하여 {T, S^2, βC}의 형태로 바줍니다.
[3]. Time-strided convolution : 2βC 의 출력 채널과 stride = α 를 가진 5×1^2 커널의 3D convolution을 사용한다고 합니다.
즉, 전체적으로 컨볼루션과 샘플링 프레임을 채널단위로 바꿔주며 Slow pathway와 Fast pathway를 맞춰줍니다.&lt;/p&gt;

&lt;h4 id=&quot;main-results&quot;&gt;&lt;strong&gt;&lt;u&gt;Main Results&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-08-SlowFast/figure3.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(figure3. Comparison with the state-of-the-art on Kinetics-400.)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-08-SlowFast/figure4.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(figure3. Accuracy/complexity tradeof.)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-11-08-SlowFast/figure5.png&quot; width=&quot;1000&quot; hight=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(figure3. Per-category AP on AVA.)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;제가 논문을 읽으면서 느낀점이 있는 몇가지 결과를 가지고 왔습니다. 
figure3 의 경우 Kinetics 데이터에서 Resnet 101을 백본으로 사용한 SlowFast 네트워크가 Opticalflow 를 사용한 다른 네트워크보다 좋은 성능을 보이면서
영상 인식에서 이제는 Opticalflow 보다는 RGB 채널을 통한 접근이 더 발전할 것으로 보입니다.
figure4 의 경우 SlowFast Network 에서 Slow만 단일적으로 사용했을 때보다 Slow와 Fast를 같이 사용했을 때 더 효율적인 모습이 보여졌으며 네트워크가 깊어 질수록
더 좋은 성능을 보여주었습니다.
figure5 의 경우 Fast Pathway 의 문제점이라고 할 수 있는 점이 보였습니다. 위에서 말했듯이, Slow와 Fast를 같이 썼을 경우에 전체적으로 성능향상이 있었으나 몇가지 행동은
그런게 많은 행동의 변화가 없는 경우가 있었습니다. Fast Pathway의 역할이 중요하지 않은 행동들 즉 잠을 자거나, 핸드폰으로 통화를 하는 등 움직임이 별로 없는 행동에서는 Slow Pathway 만 단독적으로 썼을 때가 더 성능이 좋았습니다. 이런 점을 보면 Fast Pathway가 정적인 행동에서는 긍정적인 영향을 미치지 않으며, 정적인 행동에서는 다른 접근법이 필요하다고 저는 느껴졌습니다.&lt;/p&gt;

&lt;p&gt;이상 SlowFast 논문 리뷰를 마치며 읽어주신 분들께 감사드리며, 틀린 점이나 고쳐야 될 부분은 댓글이나 mwlee0860@gmail.com 으로 메일을 보내주시면 감사하겠습니다.&lt;/p&gt;</content>

      
      
      
      
      

      <author>
          <name>Sangwoo Lee</name>
        
        
      </author>

      

      
        <category term="paper-review" />
      

      
        <summary type="html">안녕하세요? 이번에 SlowFast 논문 Review를 하게된 AirLab 이상우입니다.</summary>
      

      
      
    </entry>
  
</feed>
