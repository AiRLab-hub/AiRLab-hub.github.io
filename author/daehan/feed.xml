<?xml version="1.0" encoding="utf-8"?>

<feed xmlns="http://www.w3.org/2005/Atom" >
  <generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator>
  <link href="https://blog.airlab.re.kr/author/daehan/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://blog.airlab.re.kr/" rel="alternate" type="text/html" />
  <updated>2019-10-01T16:27:12+09:00</updated>
  <id>https://blog.airlab.re.kr/author/daehan/feed.xml</id>

  
  
  

  
    <title type="html">AiRLab. Research Blog | </title>
  

  
    <subtitle>Artificial intelligence and Robotics Laboratory</subtitle>
  

  

  
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
  

  
    <entry>
      <title type="html">R-CNN</title>
      <link href="https://blog.airlab.re.kr/2019/10/R-CNN" rel="alternate" type="text/html" title="R-CNN" />
      <published>2019-10-01T00:00:00+09:00</published>
      <updated>2019-10-01T00:00:00+09:00</updated>
      <id>https://blog.airlab.re.kr/2019/10/R-CNN</id>
      <content type="html" xml:base="https://blog.airlab.re.kr/2019/10/R-CNN">&lt;p&gt;R-CNN Review&lt;/p&gt;

&lt;p&gt;안녕하세요. &lt;strong&gt;AiRLab&lt;/strong&gt;(한밭대학교 인공지능 및 로보틱스 연구실) 김대한 입니다. R-CNN을 시작으로 paper review post 를 작성하려고 합니다. ^_^&lt;/p&gt;

&lt;p&gt;이번에 읽은 논문은 &lt;strong&gt;R-CNN&lt;/strong&gt;(Rich feature hierarchies for accurate object detection and semantic segmentation) (&lt;a href=&quot;https://arxiv.org/abs/1311.2524&quot;&gt;arXiv:1311.2524&lt;/a&gt;)입니다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;introduciton&quot;&gt;&lt;strong&gt;&lt;u&gt;Introduciton&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;논문 발표 이전&lt;strong&gt;SIFT&lt;/strong&gt;와 &lt;strong&gt;HOG&lt;/strong&gt; 에 상당한 기반을 두고 visual recognition task를 수행했다고 합니다. 그러나 낮은 perpomance 로인해 R-CNN을 고안 하였습니다. 
여기서 SIFT와 HOG를 간단하게 설명하면, 다음과 같습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;u&gt;SIFT&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/2019-10-01-R-CNN/figure1.jpg&quot; alt=&quot;figure1&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt; SIFT feature vector는 feature 주변의 영상패치를 4x4 블럭으로 나누고, (1) 각 블럭에 속한 pixel들의 gradient방향과 크기에 대한 histogram을 구하고 bin값으로 연결한 128차원 벡터 입니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;크기, 형태, 방향에 강인하면서도 구분력이 뛰어나다.&lt;/li&gt;
  &lt;li&gt;기하학적 정보는 무시하고 feature 단위로 매칭을 수행한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;&lt;u&gt;HOG&lt;/u&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/posts/2019-10-01-R-CNN/figure2.jpg&quot; alt=&quot;figure2&quot; /&gt;&lt;br /&gt;
 HOG 는 대상 영역을 일정 셀로 분할한뒤, 각 셀마다 edge pixel들의 방향에 대한 histogram을 구한 뒤 이를 bin값으로 연결한 벡터 이다. (edge의 방향 histogram으로 본다.)&lt;br /&gt;
블록 단위로는 기하학적 정보를 유지하고, 그 내부는 histogram을 사용하여 local변화에 어느정도 강인하다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;template matching과 histogram maching에 중간 단계의 매칭방법이다.&lt;/li&gt;
  &lt;li&gt;기하학적 정보와 local 한 정보를 모두(일정 양) 가진다.&lt;/li&gt;
  &lt;li&gt;figure2를 보면 알겠지만 edge의 방향정보를 사용하기 때문에 특이한(독특한) edge를 갖는 object를 식별하는데 적합한 영상 feature이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;SIFT/HOG&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;SIFT&lt;/th&gt;
      &lt;th&gt;HOG&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;이용하는 정보&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;local information&lt;/td&gt;
      &lt;td&gt;edge information&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;형태변화가 심한 경우 detection&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;esay&lt;/td&gt;
      &lt;td&gt;difficult&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;example&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;액자속 그림(패턴)&lt;/td&gt;
      &lt;td&gt;자동차, 배드민턴 라켓&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;**&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;복잡한 image&lt;/td&gt;
      &lt;td&gt;단순하고 독특한 image&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;이 논문에서는 &lt;strong&gt;HOG 기반의 시스템 보다 CNN을 사용하여 높은 performance를 보여주기 위해 2가지 문제&lt;/strong&gt;에 초점을 맞춥니다.&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;u&gt;[One]&lt;/u&gt; sliding-window 의 문제점을 파악하고 region proposal Algorithm을 사용했다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-10-01-R-CNN/figure4.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(sliding-window method)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-10-01-R-CNN/figure5.png&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(region-proposal method)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sliding window는 탐색해야하는 영역의 수가 이미지 전체이기 때문에 비효율적이고 입력 영상에 ‘물체가 있을거 같은’ 영역을 빠른 속도로 찾아내는 region proposal algorithm을 사용 하였다.&lt;br /&gt;
&lt;strong&gt;결과적으로 search space가 훨씬 줄어들기 때문에 빠르고 효율적 이다.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;u&gt;[Two]&lt;/u&gt; large CNN을 training하기 위한 충분한 dataset이 없었고, ILSVRC DATA로 pre-training 된 model을 가져와서 fine-tune 하여 PASCAL DATA에 적용하였다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;object-detection-with-r-cnn&quot;&gt;&lt;strong&gt;&lt;u&gt;object detection with R-CNN&lt;/u&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;                   R-CNN은 3가지의 module 로 구성되어 있습니다.
&lt;img src=&quot;/assets/images/posts/2019-10-01-R-CNN/figure3.png&quot; alt=&quot;figure3&quot; /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;region proposal을 얻어내는 module&lt;/li&gt;
  &lt;li&gt;CNN에 넣어 feture map을 얻어내는 module&lt;/li&gt;
  &lt;li&gt;CNN을 통해 추출된 feture map을 이용하여 Linear SVM을 사용하여 분류하는 module&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이때, CNN model은 Alexnet을 거의 그대로 가져와 사용하였다.&lt;br /&gt;
당연히 CNN은 고정 크기의 input을 입력으로 받기 때문에. region proposal을 CNN에 넣기 위해 crop &amp;amp; warp 를 한다.
논문에 나와있지만, 읽다보면 왜 R-CNN은 Classifier로 Softmax를 쓰지 않고 SVM을 사용했는지에 대한 의문이 들 수 있다. 근데 이는 수식적에 근간을 두고 사용한 것이 아닌 실험적인 결과로 Softmax를 사용했을때 mAP가 낮아졌기 때문에 SVM을 사용한 것 이다.(54.2% -&amp;gt; 50.9%)&lt;/p&gt;

&lt;p&gt;SVM을 간단하게 설명하면 CNN으로 부터 추출된 featuer vector들을 class별로 점수를 주고 object인지 아닌지 object라면 어떤 object 인지 판별하는 classifier이다.&lt;/p&gt;

&lt;p&gt;figure를 보면 Bbox reg 라는 부분이 있는데 bounding Box Regression인데 이는 필수로 사용해야 하는 부분은 아니라고 한다. 그러나 사용한 mAP가 더 좋기 때문에 사용하는 것을 권장한다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-10-01-R-CNN/figure6.png&quot; width=&quot;400&quot; height=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(Bounding-box method)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;
ground-truth(G) 와 Predicted-Box(P) 가 있을때, P를 G로 mapping 해주는 것이다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-10-01-R-CNN/figure7.png&quot; width=&quot;600&quot; height=&quot;300&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(Result)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;
결과적으로, 다음과 같은 output을 얻을 수 있다.&lt;/p&gt;
&lt;hr /&gt;

&lt;h4 id=&quot;논문을-읽으면서-여러자료들을-참고하여-r-cnn의-단점을-이해해-보았다&quot;&gt;&lt;u&gt;논문을 읽으면서 여러자료들을 참고하여 R-CNN의 단점을 이해해 보았다.&lt;/u&gt;&lt;/h4&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/posts/2019-10-01-R-CNN/figure8.png&quot; width=&quot;900&quot; height=&quot;200&quot; /&gt;&lt;/center&gt;
&lt;center&gt;(Table)&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;
위와 같이 VOC2010 test에서 좋은 성능을 보였지만 단점은 존재한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;region proposal된 약 2K의 image를 모두 crop하고 warp하는 과정에서 cpu를 통해 이뤄지기 때문에, 매우 비효율 적이라는 점을 이해하였다.&lt;br /&gt;
&lt;strong&gt;직접 경험해본 일화&lt;/strong&gt;중 하나는, 1980x1080 를 224x224 image preprocessing 하는 과정이 오래걸려서 GPU가 놀고 있는 시간이 많았던 적이 있다. (224x224 image를 따로 저장하여 문제 해결.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;3가지의 module을 따로 학습해야하기 때문에 비효율적이다.
&lt;strong&gt;때문에 Fast_R-CNN에서 Multi-task loss&lt;/strong&gt;를 사용한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;end-to-end 학습이 불가능 하다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content>

      
      
      
      
      

      <author>
          <name>Daehan Kim</name>
        
        
      </author>

      

      
        <category term="paper-review" />
      

      
        <summary type="html">R-CNN Review</summary>
      

      
      
    </entry>
  
</feed>
