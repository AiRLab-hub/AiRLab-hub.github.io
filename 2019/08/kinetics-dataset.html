<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Artificial intelligence and Robotics Laboratory" />
    <link rel="shortcut icon" href="http://localhost:4000/assets/images/favicon.png" type="image/png" />
    <link rel="canonical" href="http://localhost:4000/2019/08/kinetics-dataset" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="AiRLab. Research Blog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset" />
    <meta property="og:description" content="Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset 리뷰 안녕하세요. AiRLab(한밭대학교 인공지능 및 로보틱스 연구실) 서민석입니다. 제가 이번에 리뷰할 논문은 제목에도 써 있는것과 같이 “Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset” 입니다. 이 논문은 딥마인드에서 발표한 kinetics dataset 논문입니다. 이 논문은 데이터셋 논문임에도" />
    <meta property="og:url" content="http://localhost:4000/2019/08/kinetics-dataset" />
    <meta property="og:image" content="http://localhost:4000/assets/images/posts/2019-08-04-kinetics-dataset/cover.PNG" />
    <meta property="article:publisher" content="https://www.facebook.com/false" />
    <meta property="article:author" content="https://www.facebook.com/false" />
    <meta property="article:published_time" content="2019-08-03T17:00:00+09:00" />
    <meta property="article:modified_time" content="2019-08-03T17:00:00+09:00" />
    <meta property="article:tag" content="Paper-review" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset" />
    <meta name="twitter:description" content="Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset 리뷰 안녕하세요. AiRLab(한밭대학교 인공지능 및 로보틱스 연구실) 서민석입니다. 제가 이번에 리뷰할 논문은 제목에도 써 있는것과 같이 “Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset” 입니다. 이 논문은 딥마인드에서 발표한 kinetics dataset 논문입니다. 이 논문은 데이터셋 논문임에도" />
    <meta name="twitter:url" content="http://localhost:4000/" />
    <meta name="twitter:image" content="http://localhost:4000/assets/images/posts/2019-08-04-kinetics-dataset/cover.PNG" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="AiRLab. Research Blog" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Paper-review" />
    <meta name="twitter:site" content="@false" />
    <meta name="twitter:creator" content="@false" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "AiRLab. Research Blog",
        "logo": "http://localhost:4000/assets/images/airlab-logo.png"
    },
    "url": "http://localhost:4000/2019/08/kinetics-dataset",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:4000/assets/images/posts/2019-08-04-kinetics-dataset/cover.PNG",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:4000/2019/08/kinetics-dataset"
    },
    "description": "Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset 리뷰 안녕하세요. AiRLab(한밭대학교 인공지능 및 로보틱스 연구실) 서민석입니다. 제가 이번에 리뷰할 논문은 제목에도 써 있는것과 같이 “Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset” 입니다. 이 논문은 딥마인드에서 발표한 kinetics dataset 논문입니다. 이 논문은 데이터셋 논문임에도"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset" href="/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="http://localhost:4000/"><img src="/assets/images/airlab-logo.png" alt="AiRLab. Research Blog" /></a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-notice" role="menuitem"><a href="/tag/notice/">Notice</a></li>
    <li class="nav-paper-review" role="menuitem"><a href="/tag/paper-review/">Paper-review</a></li>
    <li class="nav-try-ghost" role="menuitem"><a href="https://github.com/airlab-hub">Github</a></li>

</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime=" 3 August 2019"> 3 August 2019</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/paper-review/'>PAPER-REVIEW</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/images/posts/2019-08-04-kinetics-dataset/cover.PNG)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p>Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset 리뷰</p>

<p>안녕하세요. <strong>AiRLab</strong>(한밭대학교 인공지능 및 로보틱스 연구실) 서민석입니다. 제가 이번에 리뷰할 논문은 제목에도 써 있는것과 같이 <strong>“Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset”</strong> 입니다.</p>

<p>이 논문은 딥마인드에서 발표한 kinetics dataset 논문입니다. 이 논문은 데이터셋 논문임에도 action recognition의 역사와 방향성을 제시해주기 때문에 action recognition에 입문하시는 분들이라면 꼭 읽어 보시는 걸 추천해 드립니다.</p>

<p>기존의 action recognition 문제에서 UCF101 과 HMDB51 같은 규모가 작은 데이터셋은 좋은 성능을 내기 어려웠습니다. 그래서 이 논문 저자는 ImageNet처럼 action recognition에도 빅 데이터셋이 필요성을 느끼고 Kinetics 데이터셋을 만듭니다. Kinetics 데이터셋은 400개의 클래스들 과  한 클래스당 400개가 넘는 clips가 존재하는 빅데이터 셋입니다.(현재는 클래스 700 버전도 업로드 되었습니다.) Kinetics 데이터셋을 학습시킨 파라메터로 전이학습을 진행하여 UCF101 과 HMDB51 과 같은 작은 규모의 데이터셋에서도 좋은 성능을 냈습니다. 또한 Two-Stream Inflated 3D ConvNet (I3D)을 제안하고 전이학습을 진행하여 HMDB51에서는 80.9% UCF101에서는 98.0%를 달성하였습니다.</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/cover.PNG" alt="Image" /></p>

<h3 id="the-old-Ⅰ-convnetlstm">The Old Ⅰ: ConvNet+LSTM</h3>

<p>영상에서 25 프레임을 뽑아낸후, CNN을 돌려서 나온 결과를 LSTM으로 입력하여 sequential한 정보를 예측해 보겠다는 아이디어 입니다. 직관적으로도 배경을 제거하고 CNN에 들어가는 것이 아니기 때문에 액션보다는 배경에 큰 영향을 받고, 미세한 액션은 잘 찾지 못하는 단점이 있었습니다.(LSTM을 꼭 활용하고 싶으시다면 OCR처럼 액션을 하는 오브젝트를 디텍션한 후 크롭하는 방법을 추천 드립니다.)</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure1.PNG" alt="Image" /></p>

<h3 id="the-old-Ⅱ-3d-convnets">The old Ⅱ: 3D ConvNets</h3>

<p>action recognition에 처음 입문하시는 분들이 가장 먼저 직관적으로 예측가능 한 방법 같습니다. 하지만 3D conv는 3D 컨브보다 더 많은 파라메터가 필요하며, 이는 학습을 어렵게 만듭니다. 그리고 여전히 배경에 영향을 많이 받기 때문에 작은 행동들은 많이 놓치는 경향이 보였습니다.</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure2.PNG" alt="Image" /></p>

<h3 id="optical-flow-란">Optical flow 란?</h3>

<p>기존 영상처리에서 움직이는 객체를 추적할때 자주 사용하던 방법입니다. Optical flow를 사용하면 움직이는 객체의 x방향 y방향의 벡터를 뽑아 낼 수 있습니다. 이 논문에서는 TVL1방법을 사용 했습니다. TVL1 방법이란 두 프레임 사이의 변화한 점을 픽셀 단위로 추적하면서, 데이터 사이의 차이를 L1 norm으로 구하고, 전체 데이터의 분산을 사용하여 정규화 하는 방법입니다.(딥러닝을 사용하지 않고 Optical flow를 뽑는 방법중 가장 쓸만한 방법 입니다.)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">optical_flow</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">DualTVL1OpticalFlow_create</span><span class="p">()</span>
<span class="n">flow</span> <span class="o">=</span> <span class="n">optical_flow</span><span class="o">.</span><span class="n">calc</span><span class="p">(</span><span class="n">prvs</span><span class="p">,</span> <span class="nb">next</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure3.PNG" alt="Image" /></p>

<h3 id="the-old-Ⅲ-two-stream-networks">The old Ⅲ: Two-Stream Networks</h3>

<p>아직도 활발한 연구가 진행되고 있는 방법이지만, 이 논문 저자는 old 라고 표기했기 때문에 old 라고 표현하겠습니다! 이 방법은 RGB와 Optical flow를 사용한 2D conv 방법입니다. Optical flow를 사용하여 행동을 예측하기 때문에 action을 비교적 잘 찾지만, 아직도 여전히 찝찝한 부분은 남아있습니다. 2D conv이기 때문에 rgb 한장 optical flow한장 들어가기 때문에 한 영상에서 뽑은 프레임 사이의 관계를 예측하는 부분에서는 아직까지 뭔가 찝찝합니다. 또한 이 찝찝함을 해결하기 위하여 rgb와 optical flow에서 나온 결과를 concat하여 3D를 만든후 3D conv를 하는 방법도 있습니다.(이 방법들의 단점을 직관적으로 생각해 보면 rgb는 3D컨브를 해야 RGB프레임 간 관계를 잘 예측 할 수 있기 떄문에 이 방법들은 RGB간 관계를 알기 힘들어서 정확도가 낮게 나온다고 생각합니다. 혹시 이 부분이 틀리다면 댓글로 지적 부탁드립니다.)</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure4.PNG" alt="Image" /></p>

<h3 id="the-new-two-stream-inflated-3d-convnets">The New: Two-Stream Inflated 3D ConvNets</h3>

<p>RGB와 Optical flow를 동시에 활용한다는 면에서 Two-Stream 방법이고, 2D conv가 아니라 3D conv이기 떄문에 Two-Stream Inflated 3D ConvNets 이라고 정의하며, 앞에서 언급한 모든 방법들보다 이 논문의 실험에서는 정확도가 가장 높았습니다.
RGB를 3D conv 함으로써 시간정보를 계층적으로 만들 수 있지만, 그래도 여전히 action을 인식하기에는 부족한 면이 있기 때문에 Optical flow도 활용합니다.</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure5.PNG" alt="Image" /></p>

<h3 id="inflating-2d-convnets-into-3d">Inflating 2D ConvNets into 3D</h3>

<p>단순하게 2D conv를 3D conv로 변경하려면 시간축 디멘션 하나를 추가하고 pad를 줘서 shape를 맞춰주시면 됩니다. 논문에서 언급한 것 처럼 간단하게 N<em>N을 N</em>N*N을 만들어 주시면 됩니다.</p>

<h3 id="bootstrapping-3d-filters-from-2d-filter">Bootstrapping 3D filters from 2D Filter</h3>

<p>3D conv에서 ImageNet pre-trained 된 weight를 활용하려면 단순하게 weight를 N번 복제해 주시면 됩니다. 뭔가 직관적으로 하면 안될 것 같은 느낌이 들지만 이 논문에서는 실험적으로 이렇게 해서라도 ImageNet pre-trained된 weight를 사용하는게 좋다고 밝힙니다.</p>

<h3 id="pacing-receptive-field-growth-in-space-time-and-network-depth">Pacing receptive field growth in space, time and network depth</h3>

<p>직관적으로 당연히 공간정보와 시간정보의 stride가 적절하게 조절되어야 합니다. 공간정보는 조금 변하는데 시간정보의 stride가 많이 변하면 공간정보를 제대로 못보고, 그렇다고 시간정보의 stride가 조금 변하면 그것은 정지영상과 다름이 없어 행동을 잘 인식하지 못하게 됩니다. 이 논문 저자는 Inflated Inception-V1에서 첫 번째와 두 번째의 Max-Pool레이어에서는 시간축의 stride의 크기를 1 로 설정하면 경험적으로 더 좋았다고 합니다.</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure6.PNG" alt="Image" /></p>

<h3 id="two-3d-streams">Two 3D Streams</h3>

<p>RGB 정보만 이용해도 3D conv를 사용하면 시간정보를 볼 수 있지만, 이 논문에서는 그래도 Optical flow를 사용하면 경험적으로 더 정확도가 높았다고 합니다. 지금까지 내용을 간단하게 요약하면 아무리 3D conv를 사용하는게 좋고, 3D conv를 사용하더라도 Optical flow를 사용하는게 좋다 입니다.</p>

<h3 id="conculusion">Conculusion</h3>

<p>저는 원래 결론 쓰는 것을 좋아하진 않지만!(개인적인 견해가 들어갈 수 있기 때문에) 데이터셋 논문이기 때문에 결론을 작성하겠습니다. 논문에서 제시한 I3D방법을 사용하는 것이 정확도가 가장 높았고, 정확도 대비 파라메터가 그렇게 많지 않았습니다.</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure7.PNG" alt="Image" /></p>

<p>파라메터도 적은 편 입니다.</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure8.PNG" alt="Image" /></p>

<p>정확도도 i3d가 가장 높았으며 i3d 중에서도 optical flow도 활용하는 방법이 가장 좋았습니다.</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure9.PNG" alt="Image" /></p>

<p>앞에서도 언급했던 것 처럼 Imagenet에서 pre-trained된 것을 활용하는게 더 성능이 좋았습니다.</p>

<p><img src="/assets/images/posts/2019-08-04-kinetics-dataset/figure10.PNG" alt="Image" /></p>

<p>모든 방법에서 i3d 방법이 가장 좋았습니다.</p>

<h3 id="후기">후기</h3>

<p>이 논문은 action recognition에 입문하는 사람이라면 꼭 읽어 보시는걸 추천드리고, 아직 코드 구현은 못했습니다. 구현이 완료 되는데로 링크 첨부 하겠습니다. 읽어주셔서 감사합니다.</p>


                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                    
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/images/authors/minseok.jpeg" alt="minseok" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/minseok">Minseok Seo</a></h4>
                                
                                    <p>🥟</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/minseok">Read More</a>
                        </div>
                    
                
                    
                
                    
                
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            this.page.url = 'http://localhost:4000/';
                            this.page.identifier = 'AiRLab. Research Blog';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://airlab.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            
                                style="background-image: url(url(/assets/images/posts/2019-08-04-kinetics-dataset/cover.PNG)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; AiRLab. Research Blog &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/paper-review/">Paper-review</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/2019/08/upernet">Unified Perceptual Parsing for Scene Understanding</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/2019/08/Group-Normalization">Group Normalization</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/2019/08/resnext">ResNeXt:Aggregated Residual Transformations for Deep Neural Networks</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/paper-review/">
                                
                                    See all 8 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/2019/08/resnext">
                <div class="post-card-image" style="background-image: url(/assets/images/posts/2019-08-20-resnext/01.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/2019/08/resnext">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Paper-review</span>
                            
                        
                    

                    <h2 class="post-card-title">ResNeXt:Aggregated Residual Transformations for Deep Neural Networks</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p></p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/images/authors/soyeol.jpeg" alt="Soyeol Lee" />
                        
                        <span class="post-card-author">
                            <a href="/author/soyeol/">Soyeol Lee</a>
                        </span>
                    
                
                    
                
                    
                
                <span class="reading-time">
                    
                    
                      1 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/2019/07/rkd">
                <div class="post-card-image" style="background-image: url(/assets/images/posts/2019-07-24-rkd/cover.png)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/2019/07/rkd">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Paper-review</span>
                            
                        
                    

                    <h2 class="post-card-title">Relational Knowledge Distillation</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p></p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/images/authors/jaemin.jpeg" alt="Jaemin Lee" />
                        
                        <span class="post-card-author">
                            <a href="/author/jaemin/">Jaemin Lee</a>
                        </span>
                    
                
                    
                
                    
                
                    
                
                    
                
                <span class="reading-time">
                    
                    
                      1 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="http://localhost:4000/">
            
                <img src="/assets/images/favicon.png" alt="AiRLab. Research Blog icon" />
            
            <span>AiRLab. Research Blog</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Quo+Vadis%2C+Action+Recognition%3F+A+New+Model+and+the+Kinetics+Dataset&amp;url=https://blog.airlab.re.kr/2019/08/kinetics-dataset"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://blog.airlab.re.kr/2019/08/kinetics-dataset"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="http://localhost:4000/">AiRLab. Research Blog</a> &copy; 2019</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyller/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-144039873-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
